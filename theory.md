#### 什么是线性回归

线性回归，即是用线性模型来做数值-数值预测，用于训练的数据长这样：$[(x_0,x_1,\cdots,x_k), y]$，简写成这样：$[\mathbb x, y]$,模型要实现的目的是经过这类型的数据训练后，对于同类型的数据，可以通过 $\mathbb x$ 来估计（或者说预测）$y$。

线性回归的模型长这样：

$$
\hat y = w_0x_0+w_1x_1+\cdots+w_kx_k+b
$$

可以简写成（其实就是向量点积，只不过写成矩阵乘法的形式）：

$$
\hat y = \mathbb{w}^T\mathbb{x}+b
$$

模型的样子也就决定了它就算只能做数值-数值预测，但它发挥比较好的也就这类问题的某些子集。

#### 预备知识：向量求导

写这节是为了让读者能看懂后面的公式，原书略过了一些细节，对新手比较致命。

首先要先对矩阵求导有个基本印象，这里可以看我写的 [矩阵求导 (isirin1131.github.io)](https://isirin1131.github.io/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC.html)。

其次，我们不需要对完整的矩阵求导建立代数系统，而只需要对向量求导建立理论和得出并记住一些基本结果，这对理解线性回归这一节中的公式已经足够了。（其实是我搞不定更高的理论）
